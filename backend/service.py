"""
íƒ€ë¡œ ì¹´ë“œ í•´ì„ ì„œë¹„ìŠ¤ ë ˆì´ì–´
ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ë° ì™¸ë¶€ API í˜¸ì¶œì„ ë‹´ë‹¹
"""
import requests
import os
from typing import List, Tuple, Dict
from dotenv import load_dotenv

from const import (
    CARD_MEANINGS,
    TAROT_READER_SYSTEM_PROMPT,
    INTERPRETATION_PROMPT_TEMPLATE,
    FOLLOWUP_SYSTEM_PROMPT,
    FOLLOWUP_PROMPT_TEMPLATE,
    SPREAD_TYPE_ONE_CARD,
    SPREAD_TYPE_THREE_CARD,
    DEFAULT_ADVICE,
    RESPONSE_PARSE_KEYWORD_ADVICE,
    RESPONSE_PARSE_KEYWORD_INTERPRETATION,
    RESPONSE_PARSE_KEYWORD_CHAR_COUNT_200_300,
    RESPONSE_PARSE_KEYWORD_CHAR_COUNT_100_150,
    DEFAULT_TEMPERATURE,
    DEFAULT_NUM_PREDICT_INTERPRETATION,
    DEFAULT_NUM_PREDICT_FOLLOWUP,
    DEFAULT_TIMEOUT
)

load_dotenv()

# Runpod EEVE ëª¨ë¸ ì„¤ì •
RUNPOD_ID = os.getenv("RUNPOD_ID")
RUNPOD_URL = os.getenv("RUNPOD_URL", f"https://{RUNPOD_ID}-8000.proxy.runpod.net")
EEVE_MODEL = os.getenv("EEVE_MODEL")


class TarotService:
    """íƒ€ë¡œ ì¹´ë“œ í•´ì„ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.runpod_url = RUNPOD_URL
        self.eeve_model = EEVE_MODEL
        print(f"ğŸ”® Using Ollama EEVE Model: {self.eeve_model}")
        print(f"ğŸ“¡ Runpod URL: {self.runpod_url}")
        
        # í™˜ê²½ ë³€ìˆ˜ ê²€ì¦
        if not RUNPOD_ID or RUNPOD_ID == "None":
            raise ValueError("RUNPOD_ID í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        if not self.eeve_model or self.eeve_model == "None":
            raise ValueError("EEVE_MODEL í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    def get_card_keywords(self, cards: List[str]) -> str:
        """
        ì„ íƒëœ ì¹´ë“œë“¤ì˜ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì—¬ ë¬¸ìì—´ë¡œ ë°˜í™˜
        
        Args:
            cards: íƒ€ë¡œ ì¹´ë“œ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì¹´ë“œë³„ í‚¤ì›Œë“œë¥¼ í¬í•¨í•œ ë¬¸ìì—´
        """

        card_context = []
        for card_name in cards:
            if card_name in CARD_MEANINGS:
                keywords = ", ".join(CARD_MEANINGS[card_name])
                card_context.append(f"{card_name}: {keywords}")
        
        return "\n".join(card_context)
    
    def determine_spread_type(self, cards: List[str]) -> str:
        """
        ì¹´ë“œ ê°œìˆ˜ì— ë”°ë¼ ìŠ¤í”„ë ˆë“œ íƒ€ì… ê²°ì •
        
        Args:
            cards: íƒ€ë¡œ ì¹´ë“œ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ìŠ¤í”„ë ˆë“œ íƒ€ì… ë¬¸ìì—´
        """
        return SPREAD_TYPE_ONE_CARD if len(cards) == 1 else SPREAD_TYPE_THREE_CARD
    
    def build_interpretation_prompt(
        self, 
        question: str, 
        cards: List[str]
    ) -> str:
        """
        íƒ€ë¡œ í•´ì„ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±
        
        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            cards: íƒ€ë¡œ ì¹´ë“œ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
        """
        card_info = self.get_card_keywords(cards)
        spread_type = self.determine_spread_type(cards)
        
        user_prompt = INTERPRETATION_PROMPT_TEMPLATE.format(
            spread_type=spread_type,
            question=question,
            card_info=card_info
        )

        return f"{TAROT_READER_SYSTEM_PROMPT}\n\n{user_prompt}"
    
    def call_ollama_api(
        self, 
        prompt: str, 
        model: str = None,
        temperature: float = DEFAULT_TEMPERATURE, 
        num_predict: int = DEFAULT_NUM_PREDICT_INTERPRETATION
    ) -> str:
        """
        RunPod ì»¤ìŠ¤í…€ EEVE ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ
        
        Args:
            prompt: APIì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸
            model: ì‚¬ìš©í•  ëª¨ë¸ëª… (ì‚¬ìš©ë˜ì§€ ì•ŠìŒ, í˜¸í™˜ì„± ìœ ì§€ìš©)
            temperature: ìƒì„± ì˜¨ë„ (0.0~1.0)
            num_predict: ìƒì„±í•  ìµœëŒ€ í† í° ìˆ˜
            
        Returns:
            AI ì‘ë‹µ ë¬¸ìì—´ (í”„ë¡¬í”„íŠ¸ ì œê±°ë¨)
            
        Raises:
            Exception: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        api_endpoint = f"{self.runpod_url}/generate"
        
        payload = {
            "prompt": prompt,
            "temperature": temperature,
            "max_tokens": num_predict
        }
        
        print(f"ğŸ”— Calling RunPod Endpoint: {api_endpoint}")
        print(f"ğŸ“ Prompt length: {len(prompt)} characters")
        
        try:
            response = requests.post(
                api_endpoint,
                json=payload,
                timeout=DEFAULT_TIMEOUT
            )
            
            if response.status_code != 200:
                raise Exception(
                    f"RunPod API ì˜¤ë¥˜: {response.status_code} - {response.text}"
                )
            
            data = response.json()
            text = data.get("text", "").strip()
            
            if not text:
                raise Exception("RunPodë¡œë¶€í„° ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            
            # EEVE ëª¨ë¸ì€ í”„ë¡¬í”„íŠ¸ë¥¼ í¬í•¨í•´ì„œ ë°˜í™˜í•˜ë¯€ë¡œ, í”„ë¡¬í”„íŠ¸ ë¶€ë¶„ì„ ì œê±°
            if text.startswith(prompt):
                generated_text = text[len(prompt):].strip()
                print(f"âœ‚ï¸ Removed prompt from response. Generated text length: {len(generated_text)}")
                return generated_text
            
            print(f"âš ï¸ Response doesn't start with prompt. Returning full text.")
            return text
            
        except requests.exceptions.Timeout:
            raise Exception(f"API í˜¸ì¶œ ì‹œê°„ ì´ˆê³¼ ({DEFAULT_TIMEOUT}ì´ˆ)")
        except requests.exceptions.ConnectionError:
            raise Exception(f"RunPod ì—°ê²° ì‹¤íŒ¨: {self.runpod_url}")
        except Exception as e:
            raise Exception(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    def parse_interpretation_response(self, response: str) -> Tuple[str, str]:
        """
        AI ì‘ë‹µì„ í•´ì„ê³¼ ì¡°ì–¸ìœ¼ë¡œ ë¶„ë¦¬
        
        Args:
            response: AI ëª¨ë¸ì˜ ì „ì²´ ì‘ë‹µ
            
        Returns:
            (í•´ì„, ì¡°ì–¸) íŠœí”Œ
        """
        parts = response.split(RESPONSE_PARSE_KEYWORD_ADVICE)
        
        if len(parts) == 2:
            interpretation = parts[0].replace(RESPONSE_PARSE_KEYWORD_INTERPRETATION, "").strip()
            interpretation = interpretation.replace(RESPONSE_PARSE_KEYWORD_CHAR_COUNT_200_300, "").strip()
            interpretation = interpretation.strip(":")
            
            advice = parts[1].strip()
            advice = advice.replace(RESPONSE_PARSE_KEYWORD_CHAR_COUNT_100_150, "").strip()
            advice = advice.strip(":")
        else:
            # ë¶„ë¦¬ ì‹¤íŒ¨ ì‹œ ì „ì²´ë¥¼ í•´ì„ìœ¼ë¡œ, ê°„ë‹¨í•œ ì¡°ì–¸ ìƒì„±
            interpretation = response
            advice = DEFAULT_ADVICE
        
        return interpretation.strip(), advice.strip()
    
    def interpret_tarot(self, question: str, cards: List[str]) -> Dict[str, str]:
        """
        íƒ€ë¡œ ì¹´ë“œ í•´ì„ ë©”ì¸ ë¡œì§
        
        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            cards: ì„ íƒëœ íƒ€ë¡œ ì¹´ë“œ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            í•´ì„ê³¼ ì¡°ì–¸ì„ ë‹´ì€ ë”•ì…”ë„ˆë¦¬
            
        Raises:
            Exception: í•´ì„ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ë°œìƒ ì‹œ
        """
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self.build_interpretation_prompt(question, cards)

        print("ğŸ”® Interpretation Prompt:")
        print(prompt)
        
        # Ollama API í˜¸ì¶œ (í•´ì„ìš© ê¸´ ì‘ë‹µ)
        full_response = self.call_ollama_api(
            prompt,
            temperature=DEFAULT_TEMPERATURE,
            num_predict=DEFAULT_NUM_PREDICT_INTERPRETATION
        )
        
        # ì‘ë‹µ íŒŒì‹±
        interpretation, advice = self.parse_interpretation_response(full_response)
        
        return {
            "interpretation": interpretation,
            "advice": advice
        }
    
    def build_followup_prompt(self, question: str, cards: List[str]) -> str:
        """
        ì¶”ê°€ ì§ˆë¬¸ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±
        
        Args:
            question: ì¶”ê°€ ì§ˆë¬¸
            cards: ì´ì „ì— ì„ íƒëœ ì¹´ë“œ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
        """
        cards_str = ", ".join(cards)
        
        user_prompt = FOLLOWUP_PROMPT_TEMPLATE.format(
            cards_str=cards_str,
            question=question
        )

        return f"{FOLLOWUP_SYSTEM_PROMPT}\n\n{user_prompt}"
    
    def answer_followup_question(self, question: str, cards: List[str]) -> str:
        """
        ì¶”ê°€ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±
        
        Args:
            question: ì¶”ê°€ ì§ˆë¬¸
            cards: ì´ì „ì— ì„ íƒëœ ì¹´ë“œ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            AI ë‹µë³€ ë¬¸ìì—´
            
        Raises:
            Exception: ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ ì‹œ
        """
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self.build_followup_prompt(question, cards)
        
        # Ollama API í˜¸ì¶œ (ì¶”ê°€ ì§ˆë¬¸ìš© ì§§ì€ ì‘ë‹µ)
        response = self.call_ollama_api(
            prompt, 
            temperature=DEFAULT_TEMPERATURE, 
            num_predict=DEFAULT_NUM_PREDICT_FOLLOWUP
        )
        
        return response
